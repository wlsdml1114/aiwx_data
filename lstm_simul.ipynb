{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-22 10:00:06\n",
      "LSTM evaluation..\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import configparser\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',UserWarning)\n",
    "\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch.nn.modules.conv import Conv2d, ConvTranspose2d\n",
    "from torch.nn.modules.pooling import MaxPool2d\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "from pl_examples import _DATASETS_PATH, cli_lightning_logo\n",
    "from pl_examples.basic_examples.mnist_datamodule import MNIST\n",
    "from pytorch_lightning.utilities.cli import LightningCLI\n",
    "from pytorch_lightning.utilities.imports import _TORCHVISION_AVAILABLE\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from PIL import Image, ImageDraw\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "if _TORCHVISION_AVAILABLE:\n",
    "    from torchvision import transforms\n",
    "    \n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "print((datetime.now()+timedelta(hours=9)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(\"LSTM evaluation..\")\n",
    "thr = 0.517\n",
    "class TimeseriesDataset(Dataset):   \n",
    "    '''\n",
    "    Custom Dataset subclass. \n",
    "    Serves as input to DataLoader to transform X \n",
    "      into sequence data using rolling window. \n",
    "    DataLoader using this dataset will output batches \n",
    "      of `(batch_size, seq_len, n_features)` shape.\n",
    "    Suitable as an input to RNNs. \n",
    "    '''\n",
    "    def __init__(self, X: np.ndarray,Y: np.ndarray, seq_len: int = 24):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.Y = torch.tensor(Y).float()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.seq_len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.Y[index+self.seq_len])\n",
    "\n",
    "class lstm_encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "        super(lstm_encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = input_size, num_layers = num_layers, batch_first=True)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(8560),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(8560, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 9),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        #self.linear = nn.Linear(hidden_size, input_size)   \n",
    "    def forward(self, x_input):\n",
    "        lstm_out, self.hidden = self.lstm(x_input)\n",
    "        output = self.linear(lstm_out[:,-1])\n",
    "        #weather = F.sigmoid(output[-9:])\n",
    "        #output = torch.cat((output[:-9],weather))\n",
    "        return output,lstm_out, self.hidden\n",
    "\n",
    "class lstm_decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = input_size,num_layers = num_layers, batch_first=True)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(8560),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(8560, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 9),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        #self.linear = nn.Linear(hidden_size, input_size)           \n",
    "\n",
    "    def forward(self, x_input, encoder_hidden_states):\n",
    "        lstm_out, self.hidden = self.lstm(x_input, encoder_hidden_states)\n",
    "        output = self.linear(lstm_out[:,-1])\n",
    "        #weather = F.sigmoid(output[-9:])\n",
    "        #output = torch.cat((output[:-9],weather))\n",
    "        \n",
    "        return output,lstm_out, self.hidden\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    >>> LitAutoEncoder()  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
    "    LitAutoEncoder(\n",
    "      (encoder): ...\n",
    "      (decoder): ...\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size: int = 16, input_size: int=8560):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.encoder = lstm_encoder(input_size = input_size, hidden_size = hidden_size)\n",
    "        self.decoder = lstm_decoder(input_size = input_size, hidden_size = hidden_size)\n",
    "\n",
    "        self.criterion = F.binary_cross_entropy\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        lstm_out, state,_ = self.encoder(x)\n",
    "        return lstm_out,state, _\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat,state,_ = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        #loss = torch.cat((loss,F.binary_cross_entropy(y_hat[-9:], y[-9:])))\n",
    "        self.log(\"my_loss\", loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat,state,_ = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        #loss = torch.cat((loss,F.binary_cross_entropy(y_hat[-9:], y[-9:])))\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat,state,_ = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        #loss = torch.cat((loss,F.binary_cross_entropy(y_hat[-9:], y[-9:])))\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def first_predict(self, x):\n",
    "        lstm_out,state, _ = self.encoder(x)\n",
    "        return lstm_out,state, _\n",
    "\n",
    "    def second_predict(self, x, hidden):\n",
    "        lstm_out,state, _ = self.decoder(x,hidden)\n",
    "        return lstm_out,state, _\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()    \n",
    "config.read('setting.ini', encoding='utf-8') \n",
    "\n",
    "test_path = config['path']['test_path']\n",
    "model_path = config['path']['model_path']\n",
    "\n",
    "name = 'rain'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset X loading..\n",
      "rain target loading..\n",
      "rain model loading..\n",
      "rain predict start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "timestep = 24\n",
    "seq_len = 24\n",
    "print('dataset X loading..')\n",
    "dataset = np.load(os.path.join(test_path,'processed_data/LSTM_X.npy'))\n",
    "\n",
    "print(name,'target loading..')\n",
    "target = np.load(os.path.join(test_path,'processed_data/LSTM_'+name+'.npy'))\n",
    "\n",
    "print(name,'model loading..')\n",
    "model = LitAutoEncoder.load_from_checkpoint(os.path.join(model_path,name+'.ckpt'))\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "original_list = []\n",
    "result_list = []\n",
    "\n",
    "print(name,'predict start')\n",
    "start = 0\n",
    "test_set = dataset[start:start+timestep]\n",
    "original = target[start+timestep:start+timestep+seq_len]\n",
    "original_list.append(original.flatten())\n",
    "test_set = torch.Tensor(test_set).cuda()\n",
    "test_set = test_set.reshape(1,test_set.shape[0],test_set.shape[1])\n",
    "\n",
    "output,state,hidden = model.first_predict(test_set)\n",
    "temp_result = output.cpu().detach().numpy()\n",
    "state= state[:,-1]\n",
    "test_set = torch.cat([test_set[:,1:],state.reshape(1,state.shape[0],state.shape[1])],dim=1)\n",
    "\n",
    "for i in range(seq_len-1):\n",
    "    output,state,hidden = model.second_predict(test_set,hidden)\n",
    "    temp_result = np.concatenate([temp_result,output.cpu().detach().numpy()])\n",
    "    state= state[:,-1]\n",
    "    test_set = torch.cat([test_set[:,1:],state.reshape(1,state.shape[0],state.shape[1])],dim=1)\n",
    "    \n",
    "\n",
    "temp_result[temp_result >thr] = 1\n",
    "temp_result[temp_result <=thr] = 0\n",
    "temp_result\n",
    "#result_list.append(np.array(temp_result).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
